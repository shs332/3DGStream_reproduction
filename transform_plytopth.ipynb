{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "572e046c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06981dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scene.gaussian_model import GaussianModel\n",
    "import os, sys\n",
    "from plyfile import PlyData, PlyElement\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337e5082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ply(plydata):\n",
    "    xyz = np.stack((np.asarray(plydata.elements[0][\"x\"]),\n",
    "                    np.asarray(plydata.elements[0][\"y\"]),\n",
    "                    np.asarray(plydata.elements[0][\"z\"])),  axis=1)\n",
    "    opacities = np.asarray(plydata.elements[0][\"opacity\"])\n",
    "\n",
    "    features_dc = np.zeros((xyz.shape[0], 3, 1))\n",
    "    features_dc[:, 0, 0] = np.asarray(plydata.elements[0][\"f_dc_0\"])\n",
    "    features_dc[:, 1, 0] = np.asarray(plydata.elements[0][\"f_dc_1\"])\n",
    "    features_dc[:, 2, 0] = np.asarray(plydata.elements[0][\"f_dc_2\"])\n",
    "\n",
    "    extra_f_names = [p.name for p in plydata.elements[0].properties if p.name.startswith(\"f_rest_\")]\n",
    "    extra_f_names = sorted(extra_f_names, key = lambda x: int(x.split('_')[-1]))\n",
    "    # print(extra_f_names)\n",
    "    assert len(extra_f_names)==3*(1 + 1) ** 2 - 3 # 3*(4) for 4DGS, 3*(2) for 3DGStream\n",
    "    features_extra = np.zeros((xyz.shape[0], len(extra_f_names)))\n",
    "    for idx, attr_name in enumerate(extra_f_names):\n",
    "        features_extra[:, idx] = np.asarray(plydata.elements[0][attr_name])\n",
    "    # Reshape (P,F*SH_coeffs) to (P, F, SH_coeffs except DC)\n",
    "    features_extra = features_extra.reshape((features_extra.shape[0], 3, (1 + 1) ** 2 - 1))\n",
    "    \n",
    "    # shN = features_extra.transpose((0, 2, 1))\n",
    "\n",
    "    scale_names = [p.name for p in plydata.elements[0].properties if p.name.startswith(\"scale_\")]\n",
    "    scale_names = sorted(scale_names, key = lambda x: int(x.split('_')[-1]))\n",
    "    scales = np.zeros((xyz.shape[0], len(scale_names)))\n",
    "    for idx, attr_name in enumerate(scale_names):\n",
    "        scales[:, idx] = np.asarray(plydata.elements[0][attr_name])\n",
    "\n",
    "    rot_names = [p.name for p in plydata.elements[0].properties if p.name.startswith(\"rot\")]\n",
    "    rot_names = sorted(rot_names, key = lambda x: int(x.split('_')[-1]))\n",
    "    rots = np.zeros((xyz.shape[0], len(rot_names)))\n",
    "    for idx, attr_name in enumerate(rot_names):\n",
    "        rots[:, idx] = np.asarray(plydata.elements[0][attr_name])\n",
    "\n",
    "    # TODO: turn into tensor(with cuda device), and dimension check\n",
    "    return {'means': torch.tensor(xyz, device='cuda').float(),\n",
    "            'opacities': torch.tensor(opacities, device='cuda').float(),\n",
    "            'quats': torch.tensor(rots, device='cuda').float(),\n",
    "            'scales': torch.tensor(scales, device='cuda').float(),\n",
    "            'sh0': torch.tensor(features_dc, device='cuda').float().transpose(1, 2).contiguous(),\n",
    "            'shN': torch.tensor(features_extra, device='cuda').float().transpose(1, 2).contiguous(),\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce4a262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "means shape: torch.Size([29360, 3])\n",
      "opacities shape: torch.Size([29360])\n",
      "quats shape: torch.Size([29360, 4])\n",
      "scales shape: torch.Size([29360, 3])\n",
      "sh0 shape: torch.Size([29360, 1, 3])\n",
      "shN shape: torch.Size([29360, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "ply_before = \"/data2/wlsgur4011/3DGStream_reproduction/models/Diva360/dog/point_cloud/iteration_15000/point_cloud.ply\" # before\n",
    "\n",
    "ply_before = PlyData.read(ply_before)\n",
    "ply_before = process_ply(ply_before)\n",
    "\n",
    "for key, value in ply_before.items():\n",
    "    print(f'{key} shape:', value.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "600e1eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process(input_dict):\n",
    "    return {'step': None,    \n",
    "            'splats': input_dict,           \n",
    "            'clustered': None}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d05812",
   "metadata": {},
   "source": [
    "### Change \"ply_path\" for each directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee005950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: selective path\n",
    "output_path = '/data2/wlsgur4011/3DGStream_reproduction/output/Diva360'\n",
    "for object in os.listdir(output_path):\n",
    "    ply_path = os.path.join(output_path, object, 'point_cloud/iteration_250/point_cloud.ply')\n",
    "    temp = PlyData.read(ply_path)\n",
    "    ckpt = process_ply(temp)\n",
    "    ckpt = post_process(ckpt)\n",
    "\n",
    "    ckpt_path = os.path.join(os.path.split(ply_path)[0], 'checkpoint.pth')\n",
    "    # print(ckpt_path)\n",
    "    torch.save(ckpt, ckpt_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Reproduction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
